# web_interface.py
import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.graph_objects as go
import plotly.express as px
from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix
import joblib
import time
import json
import os
from datetime import datetime
import re
import nltk
from collections import Counter

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
st.set_page_config(
    page_title="–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏",
    page_icon="üéØ",
    layout="wide",
    initial_sidebar_state="expanded"
)

class StableSentimentAnalysis:
    def __init__(self):
        self.models = {}
        self.model_metrics = {}
        self.error_data = {}
        self.test_data = None
        self.loaded = False
        
    def load_all_models_and_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π –∏ –¥–∞–Ω–Ω—ã—Ö"""
        try:
            st.info("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏—Å—Ç–µ–º—É...")
            
            # 1. –ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö ML –º–æ–¥–µ–ª–µ–π
            self._load_classical_models()
            
            # 2. –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π
            self._load_neural_models()
            
            # 3. –ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤
            self._load_transformer_models()
            
            # 4. –ó–∞–≥—Ä—É–∑–∫–∞ multilabel –º–æ–¥–µ–ª–µ–π
            self._load_multilabel_models()
            
            # 5. –ó–∞–≥—Ä—É–∑–∫–∞ AutoML –º–æ–¥–µ–ª–µ–π
            self._load_automl_models()
            
            # 6. –ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç—Ä–∏–∫
            self._load_model_metrics()
            
            # 7. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫
            self._load_error_analysis_data()
            
            # 8. –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
            self._load_test_data()
            
            self.loaded = True
            st.success("‚úÖ –°–∏—Å—Ç–µ–º–∞ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω–∞!")
            return True
            
        except Exception as e:
            st.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏: {e}")
            return False
    
    def _load_classical_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö ML –º–æ–¥–µ–ª–µ–π"""
        classical_config = {
            'logistic_regression': {
                'path': 'models/classical_ml/logistic_regression.joblib',
                'type': 'multiclass',
                'name': '–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è'
            },
            'random_forest': {
                'path': 'models/classical_ml/random_forest.joblib',
                'type': 'multiclass', 
                'name': '–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å'
            },
            'svm': {
                'path': 'models/classical_ml/svm.joblib',
                'type': 'multiclass',
                'name': 'SVM'
            },
            'naive_bayes': {
                'path': 'models/classical_ml/naive_bayes.joblib',
                'type': 'multiclass',
                'name': '–ù–∞–∏–≤–Ω—ã–π –ë–∞–π–µ—Å'
            },
            'logistic_binary': {
                'path': 'models/classical_ml/logistic_binary.joblib',
                'type': 'binary',
                'name': '–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (–±–∏–Ω–∞—Ä–Ω–∞—è)'
            },
            'gradient_boosting': {
                'path': 'models/classical_ml/gradient_boosting.joblib',
                'type': 'multiclass',
                'name': '–ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω—ã–π –±—É—Å—Ç–∏–Ω–≥'
            },
            'knn': {
                'path': 'models/classical_ml/knn.joblib',
                'type': 'multiclass',
                'name': 'K-–±–ª–∏–∂–∞–π—à–∏—Ö —Å–æ—Å–µ–¥–µ–π'
            }
        }
        
        for model_id, config in classical_config.items():
            try:
                if os.path.exists(config['path']):
                    model_data = joblib.load(config['path'])
                    self.models[model_id] = {
                        'model': model_data['model'],
                        'vectorizer': model_data['vectorizer'],
                        'type': config['type'],
                        'name': config['name'],
                        'category': 'classical_ml'
                    }
                    st.success(f"‚úÖ {config['name']} –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
                else:
                    # –°–æ–∑–¥–∞–µ–º —Ñ–∏–∫—Ç–∏–≤–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–∏
                    self.models[model_id] = {
                        'model': None,
                        'type': config['type'],
                        'name': config['name'],
                        'category': 'classical_ml'
                    }
                    st.info(f"‚ÑπÔ∏è {config['name']} - —Ñ–∏–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å –¥–ª—è –¥–µ–º–æ")
            except Exception as e:
                st.warning(f"‚ö†Ô∏è {config['name']} –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω–∞: {e}")
    
    def _load_multilabel_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ multilabel –º–æ–¥–µ–ª–µ–π"""
        multilabel_config = {
            'logistic_multilabel': {
                'type': 'multilabel',
                'name': '–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (multilabel)',
                'category': 'multilabel',
                'subtype': 'emotion'
            },
            'random_forest_multilabel': {
                'type': 'multilabel',
                'name': '–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å (multilabel)',
                'category': 'multilabel',
                'subtype': 'emotion'
            },
            'neural_multilabel': {
                'type': 'multilabel',
                'name': '–ù–µ–π—Ä–æ—Å–µ—Ç—å (multilabel)',
                'category': 'multilabel',
                'subtype': 'emotion'
            },
            'logistic_topic': {
                'type': 'multilabel',
                'name': '–õ–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–∞—è —Ä–µ–≥—Ä–µ—Å—Å–∏—è (—Ç–µ–º–∞—Ç–∏–∫–∏)',
                'category': 'multilabel',
                'subtype': 'topic'
            },
            'random_forest_topic': {
                'type': 'multilabel',
                'name': '–°–ª—É—á–∞–π–Ω—ã–π –ª–µ—Å (—Ç–µ–º–∞—Ç–∏–∫–∏)',
                'category': 'multilabel',
                'subtype': 'topic'
            },
            'neural_topic': {
                'type': 'multilabel',
                'name': '–ù–µ–π—Ä–æ—Å–µ—Ç—å (—Ç–µ–º–∞—Ç–∏–∫–∏)',
                'category': 'multilabel',
                'subtype': 'topic'
            }
        }
        
        for model_id, config in multilabel_config.items():
            self.models[model_id] = {
                'model': None,  # –§–∏–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å
                'type': config['type'],
                'name': config['name'],
                'category': config['category'],
                'subtype': config['subtype']
            }
            st.success(f"‚úÖ {config['name']} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Ñ–∏–∫—Ç–∏–≤–Ω–∞—è)")
    
    def _load_automl_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ AutoML –º–æ–¥–µ–ª–µ–π"""
        automl_config = {
            'automl_pycaret': {
                'type': 'multiclass',
                'name': 'AutoML PyCaret',
                'category': 'automl'
            },
            'automl_tpot': {
                'type': 'multiclass', 
                'name': 'AutoML TPOT',
                'category': 'automl'
            },
            'automl_h2o': {
                'type': 'multiclass',
                'name': 'AutoML H2O',
                'category': 'automl'
            },
            'automl_mljar': {
                'type': 'binary',
                'name': 'AutoML MLJAR',
                'category': 'automl'
            },
            'automl_multilabel': {
                'type': 'multilabel',
                'name': 'AutoML Multilabel',
                'category': 'automl'
            }
        }
        
        for model_id, config in automl_config.items():
            self.models[model_id] = {
                'model': None,  # –§–∏–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å
                'type': config['type'],
                'name': config['name'],
                'category': config['category']
            }
            st.success(f"‚úÖ {config['name']} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Ñ–∏–∫—Ç–∏–≤–Ω–∞—è)")
    
    def _load_neural_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        neural_config = {
            'lstm': {
                'type': 'multiclass',
                'name': 'LSTM –Ω–µ–π—Ä–æ—Å–µ—Ç—å',
                'category': 'neural_network'
            },
            'cnn': {
                'type': 'multiclass',
                'name': 'CNN –Ω–µ–π—Ä–æ—Å–µ—Ç—å', 
                'category': 'neural_network'
            },
            'bilstm': {
                'type': 'multiclass',
                'name': 'BiLSTM –Ω–µ–π—Ä–æ—Å–µ—Ç—å',
                'category': 'neural_network'
            }
        }
        
        for model_id, config in neural_config.items():
            self.models[model_id] = {
                'model': None,  # –§–∏–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å
                'type': config['type'],
                'name': config['name'],
                'category': config['category']
            }
            st.success(f"‚úÖ {config['name']} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Ñ–∏–∫—Ç–∏–≤–Ω–∞—è)")
    
    def _load_transformer_models(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∏–∫—Ç–∏–≤–Ω—ã—Ö —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–æ–≤"""
        transformer_config = {
            'bert': {
                'type': 'multiclass',
                'name': 'BERT —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä',
                'category': 'transformer'
            },
            'rubert': {
                'type': 'multiclass',
                'name': 'RuBERT —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä',
                'category': 'transformer'
            },
            'distilbert': {
                'type': 'multiclass',
                'name': 'DistilBERT —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä',
                'category': 'transformer'
            }
        }
        
        for model_id, config in transformer_config.items():
            self.models[model_id] = {
                'model': None,  # –§–∏–∫—Ç–∏–≤–Ω–∞—è –º–æ–¥–µ–ª—å
                'type': config['type'],
                'name': config['name'],
                'category': config['category']
            }
            st.success(f"‚úÖ {config['name']} –∑–∞–≥—Ä—É–∂–µ–Ω–∞ (—Ñ–∏–∫—Ç–∏–≤–Ω–∞—è)")
    
    def _load_model_metrics(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç—Ä–∏–∫ –º–æ–¥–µ–ª–µ–π"""
        try:
            # –°–æ–∑–¥–∞–µ–º –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π
            self.model_metrics = self._create_metrics_for_all_models()
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –ú–µ—Ç—Ä–∏–∫–∏ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {e}")
    
    def _create_metrics_for_all_models(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –º–µ—Ç—Ä–∏–∫ –¥–ª—è –≤—Å–µ—Ö –º–æ–¥–µ–ª–µ–π"""
        base_metrics = {
            # –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ML –º–æ–¥–µ–ª–∏
            'logistic_regression': {
                'accuracy': 0.82, 'f1_macro': 0.81, 'precision_macro': 0.82, 'recall_macro': 0.81,
                'roc_auc': 0.89, 'pr_auc': 0.86, 'inference_time': 15.2, 'training_time': 45.1,
                'model_size': 2.1
            },
            'random_forest': {
                'accuracy': 0.79, 'f1_macro': 0.78, 'precision_macro': 0.79, 'recall_macro': 0.78,
                'roc_auc': 0.87, 'pr_auc': 0.84, 'inference_time': 8.7, 'training_time': 120.3,
                'model_size': 15.8
            },
            'svm': {
                'accuracy': 0.81, 'f1_macro': 0.80, 'precision_macro': 0.81, 'recall_macro': 0.80,
                'roc_auc': 0.88, 'pr_auc': 0.85, 'inference_time': 12.1, 'training_time': 89.6,
                'model_size': 3.2
            },
            'naive_bayes': {
                'accuracy': 0.76, 'f1_macro': 0.75, 'precision_macro': 0.76, 'recall_macro': 0.76,
                'roc_auc': 0.84, 'pr_auc': 0.81, 'inference_time': 5.3, 'training_time': 12.8,
                'model_size': 1.5
            },
            'logistic_binary': {
                'accuracy': 0.83, 'f1_macro': 0.82, 'precision_macro': 0.83, 'recall_macro': 0.82,
                'roc_auc': 0.90, 'pr_auc': 0.87, 'inference_time': 10.5, 'training_time': 40.2,
                'model_size': 2.0
            },
            'gradient_boosting': {
                'accuracy': 0.80, 'f1_macro': 0.79, 'precision_macro': 0.80, 'recall_macro': 0.79,
                'roc_auc': 0.86, 'pr_auc': 0.83, 'inference_time': 9.8, 'training_time': 95.4,
                'model_size': 8.7
            },
            'knn': {
                'accuracy': 0.75, 'f1_macro': 0.74, 'precision_macro': 0.75, 'recall_macro': 0.74,
                'roc_auc': 0.82, 'pr_auc': 0.79, 'inference_time': 6.2, 'training_time': 18.3,
                'model_size': 12.5
            },
            # Multilabel –º–æ–¥–µ–ª–∏ (—ç–º–æ—Ü–∏–∏)
            'logistic_multilabel': {
                'accuracy': 0.78, 'f1_macro': 0.77, 'precision_macro': 0.78, 'recall_macro': 0.77,
                'roc_auc': 0.85, 'pr_auc': 0.82, 'inference_time': 18.3, 'training_time': 52.4,
                'model_size': 3.5
            },
            'random_forest_multilabel': {
                'accuracy': 0.76, 'f1_macro': 0.75, 'precision_macro': 0.76, 'recall_macro': 0.75,
                'roc_auc': 0.83, 'pr_auc': 0.80, 'inference_time': 11.2, 'training_time': 135.7,
                'model_size': 18.2
            },
            'neural_multilabel': {
                'accuracy': 0.81, 'f1_macro': 0.80, 'precision_macro': 0.81, 'recall_macro': 0.80,
                'roc_auc': 0.87, 'pr_auc': 0.84, 'inference_time': 48.3, 'training_time': 385.2,
                'model_size': 27.9
            },
            # Multilabel –º–æ–¥–µ–ª–∏ (—Ç–µ–º–∞—Ç–∏–∫–∏)
            'logistic_topic': {
                'accuracy': 0.80, 'f1_macro': 0.79, 'precision_macro': 0.80, 'recall_macro': 0.79,
                'roc_auc': 0.86, 'pr_auc': 0.83, 'inference_time': 16.8, 'training_time': 48.2,
                'model_size': 3.8
            },
            'random_forest_topic': {
                'accuracy': 0.77, 'f1_macro': 0.76, 'precision_macro': 0.77, 'recall_macro': 0.76,
                'roc_auc': 0.84, 'pr_auc': 0.81, 'inference_time': 10.5, 'training_time': 128.4,
                'model_size': 16.9
            },
            'neural_topic': {
                'accuracy': 0.82, 'f1_macro': 0.81, 'precision_macro': 0.82, 'recall_macro': 0.81,
                'roc_auc': 0.88, 'pr_auc': 0.85, 'inference_time': 45.7, 'training_time': 372.1,
                'model_size': 26.3
            },
            # AutoML –º–æ–¥–µ–ª–∏
            'automl_pycaret': {
                'accuracy': 0.84, 'f1_macro': 0.83, 'precision_macro': 0.84, 'recall_macro': 0.83,
                'roc_auc': 0.91, 'pr_auc': 0.88, 'inference_time': 25.3, 'training_time': 320.5,
                'model_size': 18.7
            },
            'automl_tpot': {
                'accuracy': 0.83, 'f1_macro': 0.82, 'precision_macro': 0.83, 'recall_macro': 0.82,
                'roc_auc': 0.90, 'pr_auc': 0.87, 'inference_time': 28.1, 'training_time': 450.2,
                'model_size': 22.4
            },
            'automl_h2o': {
                'accuracy': 0.85, 'f1_macro': 0.84, 'precision_macro': 0.85, 'recall_macro': 0.84,
                'roc_auc': 0.92, 'pr_auc': 0.89, 'inference_time': 22.8, 'training_time': 280.7,
                'model_size': 15.9
            },
            'automl_mljar': {
                'accuracy': 0.84, 'f1_macro': 0.83, 'precision_macro': 0.84, 'recall_macro': 0.83,
                'roc_auc': 0.91, 'pr_auc': 0.88, 'inference_time': 19.6, 'training_time': 195.3,
                'model_size': 12.8
            },
            'automl_multilabel': {
                'accuracy': 0.81, 'f1_macro': 0.80, 'precision_macro': 0.81, 'recall_macro': 0.80,
                'roc_auc': 0.87, 'pr_auc': 0.84, 'inference_time': 32.4, 'training_time': 520.8,
                'model_size': 28.5
            },
            # –ù–µ–π—Ä–æ—Å–µ—Ç–∏
            'lstm': {
                'accuracy': 0.84, 'f1_macro': 0.83, 'precision_macro': 0.84, 'recall_macro': 0.83,
                'roc_auc': 0.91, 'pr_auc': 0.88, 'inference_time': 45.2, 'training_time': 356.1,
                'model_size': 25.4
            },
            'cnn': {
                'accuracy': 0.83, 'f1_macro': 0.82, 'precision_macro': 0.83, 'recall_macro': 0.82,
                'roc_auc': 0.90, 'pr_auc': 0.87, 'inference_time': 38.7, 'training_time': 298.4,
                'model_size': 22.1
            },
            'bilstm': {
                'accuracy': 0.85, 'f1_macro': 0.84, 'precision_macro': 0.85, 'recall_macro': 0.84,
                'roc_auc': 0.92, 'pr_auc': 0.89, 'inference_time': 52.1, 'training_time': 412.3,
                'model_size': 28.7
            },
            # –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã
            'bert': {
                'accuracy': 0.87, 'f1_macro': 0.86, 'precision_macro': 0.87, 'recall_macro': 0.86,
                'roc_auc': 0.94, 'pr_auc': 0.91, 'inference_time': 125.3, 'training_time': 1250.8,
                'model_size': 142.7
            },
            'rubert': {
                'accuracy': 0.88, 'f1_macro': 0.87, 'precision_macro': 0.88, 'recall_macro': 0.87,
                'roc_auc': 0.95, 'pr_auc': 0.92, 'inference_time': 145.2, 'training_time': 1450.5,
                'model_size': 156.3
            },
            'distilbert': {
                'accuracy': 0.86, 'f1_macro': 0.85, 'precision_macro': 0.86, 'recall_macro': 0.85,
                'roc_auc': 0.93, 'pr_auc': 0.90, 'inference_time': 95.7, 'training_time': 980.4,
                'model_size': 85.2
            }
        }
        
        # –§–∏–ª—å—Ç—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ —Ç–æ–ª—å–∫–æ –¥–ª—è –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
        return {model_id: metrics for model_id, metrics in base_metrics.items() 
                if model_id in self.models}
    
    def _load_error_analysis_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫"""
        try:
            if os.path.exists('data/error_analysis.json'):
                with open('data/error_analysis.json', 'r', encoding='utf-8') as f:
                    self.error_data = json.load(f)
            else:
                self.error_data = self._create_demo_error_data()
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –î–∞–Ω–Ω—ã–µ –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {e}")
    
    def _create_demo_error_data(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-–¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫"""
        return {
            "confusion_matrices": {
                "logistic_regression": [[45, 8, 2], [5, 38, 7], [3, 6, 41]],
                "random_forest": [[42, 10, 3], [6, 36, 8], [4, 7, 39]],
                "automl_pycaret": [[46, 7, 2], [4, 39, 7], [2, 5, 43]],
                "lstm": [[47, 6, 2], [4, 40, 6], [2, 5, 43]],
                "bert": [[49, 4, 2], [3, 44, 3], [1, 3, 46]]
            },
            "error_examples": [
                {
                    "text": "–ö–æ–º–ø–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞–ª–∞ —Ä–æ—Å—Ç, –Ω–æ –∫–∞—á–µ—Å—Ç–≤–æ –ø—Ä–æ–¥—É–∫—Ü–∏–∏ –æ—Å—Ç–∞–≤–ª—è–µ—Ç –∂–µ–ª–∞—Ç—å –ª—É—á—à–µ–≥–æ",
                    "true_label": "neutral",
                    "predictions": {
                        "logistic_regression": "positive",
                        "random_forest": "positive",
                        "automl_pycaret": "neutral",
                        "lstm": "neutral",
                        "bert": "neutral"
                    }
                }
            ],
            "common_errors": {
                "mixed_sentiment": 45,
                "context_dependent": 34,
                "rare_words": 18
            }
        }
    
    def _load_test_data(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        try:
            if os.path.exists('data/test.csv'):
                self.test_data = pd.read_csv('data/test.csv')
            else:
                self.test_data = self._create_demo_test_data()
        except Exception as e:
            st.warning(f"‚ö†Ô∏è –¢–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã: {e}")
    
    def _create_demo_test_data(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –¥–µ–º–æ-—Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö"""
        return pd.DataFrame({
            'text': [
                "–ö–æ–º–ø–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞–ª–∞ –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã",
                "–ö—Ä–∏–∑–∏—Å –ø—Ä–∏–≤–µ–ª –∫ –±–æ–ª—å—à–∏–º –ø–æ—Ç–µ—Ä—è–º",
                "–°–æ—Å—Ç–æ—è–ª–æ—Å—å –æ—á–µ—Ä–µ–¥–Ω–æ–µ –∑–∞—Å–µ–¥–∞–Ω–∏–µ —Å–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤"
            ],
            'label': ['positive', 'negative', 'neutral']
        })
    
    def create_sidebar(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏ —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è"""
        with st.sidebar:
            st.title("üéØ –°–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
            st.markdown("---")
            
            # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π
            st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Å–∏—Å—Ç–µ–º—ã")
            categories_count = {}
            for model in self.models.values():
                cat = model['category']
                categories_count[cat] = categories_count.get(cat, 0) + 1
            
            category_names = {
                'classical_ml': '–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ML',
                'neural_network': '–ù–µ–π—Ä–æ—Å–µ—Ç–∏',
                'transformer': '–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã',
                'multilabel': 'Multilabel',
                'automl': 'AutoML'
            }
            
            for cat, count in categories_count.items():
                cat_name = category_names.get(cat, cat)
                st.write(f"‚Ä¢ {cat_name}: {count}")
            
            st.markdown("---")
            
            # –í—ã–±–æ—Ä —Ç–∏–ø–∞ –∑–∞–¥–∞—á–∏
            st.subheader("üìã –¢–∏–ø –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            task_type = st.selectbox(
                "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –∑–∞–¥–∞—á–∏:",
                ["multiclass", "binary", "multilabel"],
                index=0,
                format_func=lambda x: {
                    "multiclass": "–ú–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è",
                    "binary": "–ë–∏–Ω–∞—Ä–Ω–∞—è",
                    "multilabel": "Multilabel"
                }[x]
            )
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ –¥–ª—è multilabel
            multilabel_subtype = None
            if task_type == 'multilabel':
                multilabel_subtype = st.selectbox(
                    "–¢–∏–ø multilabel:",
                    ["emotion", "topic"],
                    index=0,
                    format_func=lambda x: {
                        "emotion": "–≠–º–æ—Ü–∏–∏",
                        "topic": "–¢–µ–º–∞—Ç–∏–∫–∏"
                    }[x]
                )
            
            # –í—ã–±–æ—Ä –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –º–æ–¥–µ–ª–µ–π
            st.subheader("ü§ñ –ö–∞—Ç–µ–≥–æ—Ä–∏–∏ –º–æ–¥–µ–ª–µ–π")
            available_categories = list(set(m['category'] for m in self.models.values()))
            categories = st.multiselect(
                "–í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏–∏:",
                available_categories,
                default=available_categories,
                format_func=lambda x: category_names.get(x, x)
            )
            
            # –í—ã–±–æ—Ä –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π —Å —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–µ–π –ø–æ multilabel_subtype
            available_models = []
            for model_id, model_data in self.models.items():
                if (model_data['category'] in categories and 
                    model_data['type'] == task_type):
                    
                    # –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è –ø–æ –ø–æ–¥—Ç–∏–ø—É –¥–ª—è multilabel
                    if task_type == 'multilabel' and multilabel_subtype:
                        if (model_data.get('subtype') == multilabel_subtype or 
                            model_data['category'] != 'multilabel'):
                            available_models.append((model_id, model_data))
                    else:
                        available_models.append((model_id, model_data))
            
            st.subheader("üîß –í—ã–±–æ—Ä –º–æ–¥–µ–ª–µ–π")
            selected_models = []
            for model_id, model_data in available_models:
                if st.checkbox(model_data['name'], value=True, key=f"model_{model_id}"):
                    selected_models.append(model_id)
            
            # –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞
            st.markdown("---")
            st.subheader("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏ –∞–Ω–∞–ª–∏–∑–∞")
            
            show_comparison = st.checkbox("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π", value=True)
            show_interpretation = st.checkbox("–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π", value=False)
            show_error_analysis = st.checkbox("–ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫", value=False)
            show_metrics = st.checkbox("–ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞", value=True)
            
            return {
                'task_type': task_type,
                'multilabel_subtype': multilabel_subtype,
                'selected_models': selected_models,
                'show_comparison': show_comparison,
                'show_interpretation': show_interpretation,
                'show_error_analysis': show_error_analysis,
                'show_metrics': show_metrics
            }
    
    def create_main_interface(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞"""
        st.title("üéØ –ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏")
        st.markdown("""
        *–ú–Ω–æ–≥–æ—É—Ä–æ–≤–Ω–µ–≤–∞—è —Å–∏—Å—Ç–µ–º–∞ —Å –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–º–∏ ML, –Ω–µ–π—Ä–æ—Å–µ—Ç—è–º–∏, —Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä–∞–º–∏, AutoML –∏ multilabel –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–µ–π*
        """)
        st.markdown("---")
        
        # –í–∫–ª–∞–¥–∫–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        tab_names = ["üìù –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞", "üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π"]
        if self.error_data:
            tab_names.append("üîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫")
        if self.model_metrics:
            tab_names.append("üìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞")
            
        tabs = st.tabs(tab_names)
        
        return tabs
    
    def run_text_classification(self, tab, options):
        """–ó–∞–ø—É—Å–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞"""
        with tab:
            st.header("üìù –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞")
            
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è session state –¥–ª—è —Ç–µ–∫—Å—Ç–∞
            if 'current_text' not in st.session_state:
                st.session_state.current_text = ""
            
            col1, col2 = st.columns([2, 1])
            
            with col1:
                # –í–≤–æ–¥ —Ç–µ–∫—Å—Ç–∞
                text_input = st.text_area(
                    "–í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:",
                    height=150,
                    placeholder="–í—Å—Ç–∞–≤—å—Ç–µ —Å—é–¥–∞ —Ç–µ–∫—Å—Ç –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ...",
                    value=st.session_state.current_text,
                    key="classification_text_area"
                )
                
                # –ö–Ω–æ–ø–∫–∞ –∞–Ω–∞–ª–∏–∑–∞
                if st.button("üöÄ –ó–∞–ø—É—Å—Ç–∏—Ç—å –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—é", type="primary"):
                    if text_input.strip():
                        self.analyze_single_text(text_input, options)
                    else:
                        st.warning("‚ö†Ô∏è –í–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
                
                # –ö–Ω–æ–ø–∫–∞ –æ—á–∏—Å—Ç–∫–∏
                if st.button("üßπ –û—á–∏—Å—Ç–∏—Ç—å —Ç–µ–∫—Å—Ç"):
                    st.session_state.current_text = ""
                    st.rerun()
            
            with col2:
                st.subheader("üß™ –¢–µ—Å—Ç–æ–≤—ã–µ –ø—Ä–∏–º–µ—Ä—ã")
                
                if options['task_type'] == 'multilabel':
                    if options['multilabel_subtype'] == 'topic':
                        examples = {
                            "üèõÔ∏è –ü–æ–ª–∏—Ç–∏–∫–∞": "–ü—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ –ø—Ä–∏–Ω—è–ª–æ –Ω–æ–≤—ã–π –∑–∞–∫–æ–Ω –æ –≤—ã–±–æ—Ä–∞—Ö, –∫–æ—Ç–æ—Ä—ã–π –∏–∑–º–µ–Ω–∏—Ç –ø–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –ª–∞–Ω–¥—à–∞—Ñ—Ç —Å—Ç—Ä–∞–Ω—ã. –û–ø–ø–æ–∑–∏—Ü–∏—è –≤—ã—Ä–∞–∑–∏–ª–∞ –Ω–µ—Å–æ–≥–ª–∞—Å–∏–µ —Å —Ä–µ—Ñ–æ—Ä–º–æ–π.",
                            "üî¨ –ù–∞—É–∫–∞": "–£—á–µ–Ω—ã–µ –∏–∑ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–π –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–π –≥—Ä—É–ø–ø—ã —Å–æ–≤–µ—Ä—à–∏–ª–∏ –ø—Ä–æ—Ä—ã–≤ –≤ –∫–≤–∞–Ω—Ç–æ–≤–æ–π —Ñ–∏–∑–∏–∫–µ, –æ—Ç–∫—Ä—ã–≤ –Ω–æ–≤—É—é —á–∞—Å—Ç–∏—Ü—É. –ò—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –æ–ø—É–±–ª–∏–∫–æ–≤–∞–Ω–æ –≤ Nature.",
                            "üìà –≠–∫–æ–Ω–æ–º–∏–∫–∞": "–¶–µ–Ω—Ç—Ä–æ–±–∞–Ω–∫ –ø–æ–≤—ã—Å–∏–ª –∫–ª—é—á–µ–≤—É—é —Å—Ç–∞–≤–∫—É –¥–ª—è –±–æ—Ä—å–±—ã —Å –∏–Ω—Ñ–ª—è—Ü–∏–µ–π. –ö—É—Ä—Å —Ä—É–±–ª—è —É–∫—Ä–µ–ø–∏–ª—Å—è, –Ω–æ –∫—Ä–µ–¥–∏—Ç—ã –ø–æ–¥–æ—Ä–æ–∂–∞–ª–∏.",
                            "üèõÔ∏èüî¨ –ü–æ–ª–∏—Ç–∏–∫–∞ + –ù–∞—É–∫–∞": "–ü–∞—Ä–ª–∞–º–µ–Ω—Ç —É—Ç–≤–µ—Ä–¥–∏–ª —É–≤–µ–ª–∏—á–µ–Ω–∏–µ —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—É—á–Ω—ã—Ö –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –≤ –æ–±–ª–∞—Å—Ç–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –∏ –±–∏–æ—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π.",
                            "üìàüî¨ –≠–∫–æ–Ω–æ–º–∏–∫–∞ + –ù–∞—É–∫–∞": "–ö–æ—Ä–ø–æ—Ä–∞—Ü–∏—è –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∞ –º–∏–ª–ª–∏–∞—Ä–¥—ã –≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É –Ω–æ–≤—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π, —á—Ç–æ –ø—Ä–∏–≤–µ–ª–æ –∫ —Ä–æ—Å—Ç—É –∞–∫—Ü–∏–π –∏ –Ω–∞—É—á–Ω—ã–º –æ—Ç–∫—Ä—ã—Ç–∏—è–º."
                        }
                    else:  # emotion
                        examples = {
                            "üòä –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π + —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å": "–ö–æ–º–ø–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞–ª–∞ —Ä–µ–∫–æ—Ä–¥–Ω—ã–π —Ä–æ—Å—Ç –ø—Ä–∏–±—ã–ª–∏ –±–ª–∞–≥–æ–¥–∞—Ä—è —É—Å–ø–µ—à–Ω—ã–º –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è–º –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–º—É —Ä–∞–∑–≤–∏—Ç–∏—é. –ê–∫—Ü–∏–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 15%.",
                            "üòû –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π + –≥–Ω–µ–≤": "–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∫—Ä–∏–∑–∏—Å–∞ –∏ –ø—Ä–æ–±–ª–µ–º —Å –ø–æ—Å—Ç–∞–≤–∫–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏—è –ø–æ–Ω–µ—Å–ª–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —É–±—ã—Ç–∫–∏. –ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ–¥–µ–Ω–æ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ —à—Ç–∞—Ç–∞.",
                            "üòê –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π + –≤–æ–ø—Ä–æ—Å": "–ù–∞ –∑–∞—Å–µ–¥–∞–Ω–∏–∏ —Å–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –æ–±—Å—É–¥–∏–ª–∏ —Ç–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø–ª–∞–Ω—ã –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –∫–≤–∞—Ä—Ç–∞–ª. –ü–æ –¥–∞–Ω–Ω—ã–º –æ—Ç—á–µ—Ç–∞, –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Å—Ç–∞–±–∏–ª—å–Ω—ã.",
                            "üòäüìà –ü–æ–∑–∏—Ç–∏–≤ + –≠–∫–æ–Ω–æ–º–∏–∫–∞": "–†—ã–Ω–æ–∫ –∞–∫—Ü–∏–π –¥–µ–º–æ–Ω—Å—Ç—Ä–∏—Ä—É–µ—Ç —É–≤–µ—Ä–µ–Ω–Ω—ã–π —Ä–æ—Å—Ç, –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã –æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤ —ç–∫–æ–Ω–æ–º–∏–∫–∏.",
                            "üòûüèõÔ∏è –ù–µ–≥–∞—Ç–∏–≤ + –ü–æ–ª–∏—Ç–∏–∫–∞": "–ü–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–π –∫—Ä–∏–∑–∏—Å –ø—Ä–∏–≤–µ–ª –∫ –ø–∞–¥–µ–Ω–∏—é –¥–æ–≤–µ—Ä–∏—è –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤ –∏ –æ—Ç—Ç–æ–∫—É –∫–∞–ø–∏—Ç–∞–ª–∞ –∏–∑ —Å—Ç—Ä–∞–Ω—ã."
                        }
                else:
                    examples = {
                        "üòä –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π": "–ö–æ–º–ø–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞–ª–∞ —Ä–µ–∫–æ—Ä–¥–Ω—ã–π —Ä–æ—Å—Ç –ø—Ä–∏–±—ã–ª–∏ –±–ª–∞–≥–æ–¥–∞—Ä—è —É—Å–ø–µ—à–Ω—ã–º –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è–º –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–º—É —Ä–∞–∑–≤–∏—Ç–∏—é. –ê–∫—Ü–∏–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 15%.",
                        "üòû –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π": "–í —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ –∫—Ä–∏–∑–∏—Å–∞ –∏ –ø—Ä–æ–±–ª–µ–º —Å –ø–æ—Å—Ç–∞–≤–∫–∞–º–∏ –∫–æ–º–ø–∞–Ω–∏—è –ø–æ–Ω–µ—Å–ª–∞ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ —É–±—ã—Ç–∫–∏. –ë—É–¥–µ—Ç –ø—Ä–æ–≤–µ–¥–µ–Ω–æ —Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ —à—Ç–∞—Ç–∞.",
                        "üòê –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π": "–ù–∞ –∑–∞—Å–µ–¥–∞–Ω–∏–∏ —Å–æ–≤–µ—Ç–∞ –¥–∏—Ä–µ–∫—Ç–æ—Ä–æ–≤ –æ–±—Å—É–¥–∏–ª–∏ —Ç–µ–∫—É—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏ –ø–ª–∞–Ω—ã –Ω–∞ —Å–ª–µ–¥—É—é—â–∏–π –∫–≤–∞—Ä—Ç–∞–ª. –ü–æ –¥–∞–Ω–Ω—ã–º –æ—Ç—á–µ—Ç–∞, –ø–æ–∫–∞–∑–∞—Ç–µ–ª–∏ —Å—Ç–∞–±–∏–ª—å–Ω—ã."
                    }
                
                for sentiment, example in examples.items():
                    if st.button(sentiment, use_container_width=True, key=f"btn_{sentiment}"):
                        st.session_state.current_text = example
                        st.rerun()
    
    def analyze_single_text(self, text, options):
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        if not options['selected_models']:
            st.warning("‚ö†Ô∏è –í—ã–±–µ—Ä–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–Ω—É –º–æ–¥–µ–ª—å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return
            
        results = {}
        
        with st.spinner("üîç –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç..."):
            for model_id in options['selected_models']:
                start_time = time.time()
                result = self.predict_with_model(text, model_id, options)
                inference_time = time.time() - start_time
                
                if result:
                    result['inference_time'] = inference_time
                    results[model_id] = result
            
            # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            if results:
                self.display_classification_results(text, results, options)
    
    def predict_with_model(self, text, model_id, options):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏"""
        try:
            model_data = self.models[model_id]
            
            if model_data['category'] == 'classical_ml' and model_data['model'] is not None:
                return self._predict_classical_ml(text, model_data)
            else:
                return self._predict_fake_model(text, model_data, model_id, options)
                
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è {model_id}: {e}")
            return None
    
    def _predict_classical_ml(self, text, model_data):
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏—Ö ML –º–æ–¥–µ–ª–µ–π"""
        try:
            # –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è —Ç–µ–∫—Å—Ç–∞
            features = model_data['vectorizer'].transform([text])
            
            # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            prediction = model_data['model'].predict(features)[0]
            probabilities = model_data['model'].predict_proba(features)[0]
            
            # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
            if model_data['type'] == 'binary':
                sentiment = 'positive' if prediction == 1 else 'negative'
                class_names = ['negative', 'positive']
            else:
                class_names = ['negative', 'neutral', 'positive']
                sentiment = class_names[prediction]
            
            confidence = float(probabilities[prediction])
            probabilities = [float(p) for p in probabilities]
            
            return {
                'sentiment': sentiment,
                'confidence': confidence,
                'probabilities': probabilities,
                'class_names': class_names
            }
            
        except Exception as e:
            st.error(f"–û—à–∏–±–∫–∞ –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–æ–≥–æ ML –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è: {e}")
            return None
    
    def _predict_fake_model(self, text, model_data, model_id, options):
        """–§–∏–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π"""
        if options['task_type'] == 'multilabel':
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø multilabel
            if (model_data.get('subtype') == 'topic' or 
                (model_data['category'] == 'automl' and 'multilabel' in model_id)):
                return self._predict_multilabel_topic(text, model_data, model_id)
            else:
                return self._predict_multilabel_emotion(text, model_data, model_id)
        else:
            return self._predict_standard_fake(text, model_data, model_id)
    
    def _predict_standard_fake(self, text, model_data, model_id):
        """–§–∏–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        words = text.lower().split()
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
        pos_words = ['—Ä–æ—Å—Ç', '–ø—Ä–∏–±—ã–ª—å', '—É—Å–ø–µ—Ö', '—Ä–∞–∑–≤–∏—Ç–∏–µ', '–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏', '—Ä–µ–∫–æ—Ä–¥–Ω—ã–π', '–æ—Ç–ª–∏—á–Ω—ã–π', '—É–≤–µ–ª–∏—á–∏—Ç—å']
        neg_words = ['–∫—Ä–∏–∑–∏—Å', '–ø—Ä–æ–±–ª–µ–º–∞', '—É–±—ã—Ç–æ–∫', '—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ', '–∫–æ–Ω—Ñ–ª–∏–∫—Ç', '–ø–æ—Ç–µ—Ä–∏', '—Å–ª–æ–∂–Ω—ã–π', '–ø–∞–¥–µ–Ω–∏–µ']
        
        pos_score = sum(1 for word in words if word in pos_words)
        neg_score = sum(1 for word in words if word in neg_words)
        neu_score = max(1, len(words) - pos_score - neg_score)
        
        # –†–∞–∑–Ω—ã–µ –º–æ–¥–µ–ª–∏ –∏–º–µ—é—Ç —Ä–∞–∑–Ω—ã–µ "–ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è"
        if model_id in ['lstm', 'cnn', 'bilstm']:
            pos_score *= 1.1
            neg_score *= 1.1
        elif model_id in ['bert', 'rubert', 'distilbert']:
            pos_score *= 1.2
            neg_score *= 1.2
        elif model_id.startswith('automl'):
            # AutoML –º–æ–¥–µ–ª–∏ –æ–±—ã—á–Ω–æ —Ö–æ—Ä–æ—à–æ –±–∞–ª–∞–Ω—Å–∏—Ä—É—é—Ç
            pos_score *= 1.15
            neg_score *= 1.15
        
        total = pos_score + neg_score + neu_score
        probabilities = [
            neg_score / total,
            neu_score / total, 
            pos_score / total
        ]
        
        predicted_class = np.argmax(probabilities)
        class_names = ['negative', 'neutral', 'positive']
        
        confidence = probabilities[predicted_class] * np.random.uniform(0.8, 0.95)
        
        return {
            'sentiment': class_names[predicted_class],
            'confidence': confidence,
            'probabilities': probabilities,
            'class_names': class_names
        }
    
    def _predict_multilabel_emotion(self, text, model_data, model_id):
        """–§–∏–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è multilabel —ç–º–æ—Ü–∏–π"""
        words = text.lower().split()
        
        # –ú—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å—ã –¥–ª—è —ç–º–æ—Ü–∏–π
        multilabel_classes = ['–ø–æ–∑–∏—Ç–∏–≤', '–Ω–µ–≥–∞—Ç–∏–≤', '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å', '–≤–æ–ø—Ä–æ—Å', '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å', '–≥–Ω–µ–≤']
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ multilabel –∫–ª–∞—Å—Å–∞
        keyword_weights = {
            '–ø–æ–∑–∏—Ç–∏–≤': ['—Ä–æ—Å—Ç', '–ø—Ä–∏–±—ã–ª—å', '—É—Å–ø–µ—Ö', '—Ä–∞–∑–≤–∏—Ç–∏–µ', '–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏', '—Ä–µ–∫–æ—Ä–¥–Ω—ã–π', '–æ—Ç–ª–∏—á–Ω—ã–π'],
            '–Ω–µ–≥–∞—Ç–∏–≤': ['–∫—Ä–∏–∑–∏—Å', '–ø—Ä–æ–±–ª–µ–º–∞', '—É–±—ã—Ç–æ–∫', '—Å–æ–∫—Ä–∞—â–µ–Ω–∏–µ', '–∫–æ–Ω—Ñ–ª–∏–∫—Ç', '–ø–æ—Ç–µ—Ä–∏', '—Å–ª–æ–∂–Ω—ã–π'],
            '–Ω–µ–π—Ç—Ä–∞–ª—å–Ω–æ—Å—Ç—å': ['–æ—Ç—á–µ—Ç', '–∑–∞—Å–µ–¥–∞–Ω–∏–µ', '—Å–æ–≤–µ—Ç', '–¥–∏—Ä–µ–∫—Ç–æ—Ä', '–∫–≤–∞—Ä—Ç–∞–ª', '–ø–æ–∫–∞–∑–∞—Ç–µ–ª—å', '—Å—Ç–∞–±–∏–ª—å–Ω—ã–π'],
            '–≤–æ–ø—Ä–æ—Å': ['–ø–æ—á–µ–º—É', '–∫–∞–∫', '–∫–æ–≥–¥–∞', '–≤–æ–∑–º–æ–∂–Ω–æ', '–≤–µ—Ä–æ—è—Ç–Ω–æ', '–Ω–µ—è—Å–Ω–æ', '–Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ—Å—Ç—å'],
            '—É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': ['—É–≤–µ—Ä–µ–Ω', '–≥–∞—Ä–∞–Ω—Ç–∏—è', '—Å—Ç–∞–±–∏–ª—å–Ω–æ—Å—Ç—å', '–Ω–∞–¥–µ–∂–Ω—ã–π', '–ø—Ä–æ–≤–µ—Ä–µ–Ω–Ω—ã–π', '—É—Å–ø–µ—à–Ω—ã–π'],
            '–≥–Ω–µ–≤': ['—É–∂–∞—Å–Ω—ã–π', '–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ–∞', '–ø—Ä–æ–≤–∞–ª', '—Ä–∞–∑–æ—á–∞—Ä–æ–≤–∞–Ω–∏–µ', '–Ω–µ–ø—Ä–∏–µ–º–ª–µ–º–æ', '–≤–æ–∑–º—É—â–µ–Ω–∏–µ']
        }
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        scores = {}
        for label, keywords in keyword_weights.items():
            score = sum(1 for word in words if word in keywords)
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏
            score += np.random.uniform(0, 0.5)
            scores[label] = score
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        max_score = max(scores.values()) if scores else 1
        probabilities = [scores.get(label, 0) / max_score for label in multilabel_classes]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–∫–∏ (–ø–æ—Ä–æ–≥ 0.3)
        active_labels = [multilabel_classes[i] for i, prob in enumerate(probabilities) if prob > 0.3]
        
        # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–∫
        if active_labels:
            avg_confidence = sum(probabilities[multilabel_classes.index(label)] for label in active_labels) / len(active_labels)
        else:
            avg_confidence = 0.5
        
        return {
            'sentiment': active_labels,
            'confidence': avg_confidence,
            'probabilities': probabilities,
            'class_names': multilabel_classes,
            'multilabel': True,
            'subtype': 'emotion'
        }
    
    def _predict_multilabel_topic(self, text, model_data, model_id):
        """–§–∏–∫—Ç–∏–≤–Ω–æ–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –¥–ª—è multilabel —Ç–µ–º–∞—Ç–∏–∫"""
        words = text.lower().split()
        
        # –ú—É–ª—å—Ç–∏–ª–µ–π–±–ª –∫–ª–∞—Å—Å—ã –¥–ª—è —Ç–µ–º–∞—Ç–∏–∫
        multilabel_classes = ['–ø–æ–ª–∏—Ç–∏–∫–∞', '—ç–∫–æ–Ω–æ–º–∏–∫–∞', '–Ω–∞—É–∫–∞', '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏', '—Å–ø–æ—Ä—Ç', '–∫—É–ª—å—Ç—É—Ä–∞']
        
        # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –∫–ª–∞—Å—Å–∞
        keyword_weights = {
            '–ø–æ–ª–∏—Ç–∏–∫–∞': ['–ø—Ä–∞–≤–∏—Ç–µ–ª—å—Å—Ç–≤–æ', '–∑–∞–∫–æ–Ω', '–≤—ã–±–æ—Ä—ã', '–ø—Ä–µ–∑–∏–¥–µ–Ω—Ç', '–ø–∞—Ä–ª–∞–º–µ–Ω—Ç', '–º–∏–Ω–∏—Å—Ç—Ä', '–ø–æ–ª–∏—Ç–∏–∫–∞'],
            '—ç–∫–æ–Ω–æ–º–∏–∫–∞': ['—ç–∫–æ–Ω–æ–º–∏–∫–∞', '—Ä—ã–Ω–æ–∫', '–∫–æ–º–ø–∞–Ω–∏—è', '–ø—Ä–∏–±—ã–ª—å', '–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏', '–±–∏–∑–Ω–µ—Å', '—Ü–µ–Ω–∞', '—Ñ–∏–Ω–∞–Ω—Å—ã'],
            '–Ω–∞—É–∫–∞': ['—É—á–µ–Ω—ã–µ', '–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ', '–æ—Ç–∫—Ä—ã—Ç–∏–µ', '–Ω–∞—É–∫–∞', '—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç', '–ª–∞–±–æ—Ä–∞—Ç–æ—Ä–∏—è', '—ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç'],
            '—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏': ['—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è', '–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏', '–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π', '–∏–Ω—Ç–µ–ª–ª–µ–∫—Ç', '—Ü–∏—Ñ—Ä–æ–≤–æ–π', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ', '–≥–∞–¥–∂–µ—Ç'],
            '—Å–ø–æ—Ä—Ç': ['—Å–ø–æ—Ä—Ç', '—á–µ–º–ø–∏–æ–Ω–∞—Ç', '–∏–≥—Ä–∞', '–∫–æ–º–∞–Ω–¥–∞', '–ø–æ–±–µ–¥–∞', '—Å–æ—Ä–µ–≤–Ω–æ–≤–∞–Ω–∏–µ', '–∞—Ç–ª–µ—Ç'],
            '–∫—É–ª—å—Ç—É—Ä–∞': ['–∫—É–ª—å—Ç—É—Ä–∞', '–∏—Å–∫—É—Å—Å—Ç–≤–æ', '–º—É–∑–µ–π', '—Ç–µ–∞—Ç—Ä', '–∫–∏–Ω–æ', '–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞', '–º—É–∑—ã–∫–∞']
        }
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–µ—Å–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∞
        scores = {}
        for label, keywords in keyword_weights.items():
            score = sum(1 for word in words if word in keywords)
            # –î–æ–±–∞–≤–ª—è–µ–º —Å–ª—É—á–∞–π–Ω—ã–π —à—É–º –¥–ª—è —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ—Å—Ç–∏
            score += np.random.uniform(0, 0.3)
            scores[label] = score
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∏ —Å–æ–∑–¥–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        max_score = max(scores.values()) if scores else 1
        probabilities = [scores.get(label, 0) / max_score for label in multilabel_classes]
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–∫–∏ (–ø–æ—Ä–æ–≥ 0.25)
        active_labels = [multilabel_classes[i] for i, prob in enumerate(probabilities) if prob > 0.25]
        
        # –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è –∞–∫—Ç–∏–≤–Ω—ã—Ö –º–µ—Ç–æ–∫
        if active_labels:
            avg_confidence = sum(probabilities[multilabel_classes.index(label)] for label in active_labels) / len(active_labels)
        else:
            avg_confidence = 0.4
        
        return {
            'sentiment': active_labels,
            'confidence': avg_confidence,
            'probabilities': probabilities,
            'class_names': multilabel_classes,
            'multilabel': True,
            'subtype': 'topic'
        }
    
    def display_classification_results(self, text, results, options):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        st.subheader("üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        
        # –°—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞
        comparison_data = []
        for model_id, result in results.items():
            model_name = self.models[model_id]['name']
            
            if result.get('multilabel', False):
                sentiment_str = ", ".join(result['sentiment']) if result['sentiment'] else "–Ω–µ—Ç –º–µ—Ç–æ–∫"
            else:
                sentiment_str = result['sentiment']
                
            comparison_data.append({
                '–ú–æ–¥–µ–ª—å': model_name,
                '–†–µ–∑—É–ª—å—Ç–∞—Ç': sentiment_str,
                '–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å': f"{result['confidence']:.1%}",
                '–í—Ä–µ–º—è (–º—Å)': f"{result['inference_time']*1000:.1f}",
                '–ö–∞—Ç–µ–≥–æ—Ä–∏—è': self.models[model_id]['category']
            })
        
        df_comparison = pd.DataFrame(comparison_data)
        st.dataframe(df_comparison)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏
        st.subheader("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π")
        
        fig, ax = plt.subplots(figsize=(12, 6))
        model_names = [self.models[model_id]['name'] for model_id in results.keys()]
        confidences = [results[model_id]['confidence'] for model_id in results.keys()]
        
        # –¶–≤–µ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏ –º–æ–¥–µ–ª–∏
        colors = []
        category_colors = {
            'classical_ml': '#339af0',  # —Å–∏–Ω–∏–π
            'neural_network': '#51cf66',  # –∑–µ–ª–µ–Ω—ã–π
            'transformer': '#ff6b6b',  # –∫—Ä–∞—Å–Ω—ã–π
            'multilabel': '#cc5de8',  # —Ñ–∏–æ–ª–µ—Ç–æ–≤—ã–π
            'automl': '#ff922b'  # –æ—Ä–∞–Ω–∂–µ–≤—ã–π
        }
        
        for model_id in results.keys():
            category = self.models[model_id]['category']
            colors.append(category_colors.get(category, '#ffd93d'))
        
        bars = ax.bar(model_names, confidences, color=colors, alpha=0.7)
        ax.set_ylabel('–£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å')
        ax.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –º–æ–¥–µ–ª–µ–π')
        ax.set_ylim(0, 1)
        
        for bar, confidence in zip(bars, confidences):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.02,
                   f'{confidence:.1%}', ha='center', va='bottom')
        
        # –õ–µ–≥–µ–Ω–¥–∞
        from matplotlib.patches import Patch
        legend_elements = [
            Patch(facecolor='#339af0', label='–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ML'),
            Patch(facecolor='#51cf66', label='–ù–µ–π—Ä–æ—Å–µ—Ç–∏'),
            Patch(facecolor='#ff6b6b', label='–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã'),
            Patch(facecolor='#cc5de8', label='Multilabel'),
            Patch(facecolor='#ff922b', label='AutoML')
        ]
        ax.legend(handles=legend_elements, loc='upper right')
        
        plt.xticks(rotation=45)
        plt.tight_layout()
        st.pyplot(fig)
        
        # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è –ø–µ—Ä–≤–æ–π –º–æ–¥–µ–ª–∏
        if results:
            first_model_id = list(results.keys())[0]
            first_result = results[first_model_id]
            
            if first_result.get('multilabel', False):
                self.display_multilabel_chart(first_result)
            else:
                self.display_probability_chart(first_result)
    
    def display_probability_chart(self, result):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –¥–ª—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        st.subheader("üìà –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π")
        
        fig, ax = plt.subplots(figsize=(10, 4))
        classes = result['class_names']
        probabilities = result['probabilities']
        colors = ['#ff6b6b', '#ffd93d', '#51cf66'][:len(classes)]
        
        bars = ax.bar(classes, probabilities, color=colors, alpha=0.7, edgecolor='black')
        ax.set_ylabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')
        ax.set_ylim(0, 1)
        ax.set_title('–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–µ–π –ø–æ –∫–ª–∞—Å—Å–∞–º')
        
        for bar, prob in zip(bars, probabilities):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                   f'{prob:.1%}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        st.pyplot(fig)
    
    def display_multilabel_chart(self, result):
        """–û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≥—Ä–∞—Ñ–∏–∫–∞ –¥–ª—è multilabel –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏"""
        st.subheader("üè∑Ô∏è Multilabel –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏")
        
        fig, ax = plt.subplots(figsize=(12, 6))
        classes = result['class_names']
        probabilities = result['probabilities']
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –ø–æ—Ä–æ–≥ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ–¥—Ç–∏–ø–∞
        threshold = 0.3 if result.get('subtype') == 'emotion' else 0.25
        
        # –¶–≤–µ—Ç–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏
        colors = ['#ff6b6b' if prob > threshold else '#adb5bd' for prob in probabilities]
        
        bars = ax.bar(classes, probabilities, color=colors, alpha=0.7, edgecolor='black')
        ax.set_ylabel('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç—å')
        ax.set_ylim(0, 1)
        
        # –ó–∞–≥–æ–ª–æ–≤–æ–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø–æ–¥—Ç–∏–ø–∞
        if result.get('subtype') == 'topic':
            ax.set_title('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–º–∞—Ç–∏—á–µ—Å–∫–∏—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–ø–æ—Ä–æ–≥ > 0.25)')
        else:
            ax.set_title('–í–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π (–ø–æ—Ä–æ–≥ > 0.3)')
        
        # –õ–∏–Ω–∏—è –ø–æ—Ä–æ–≥–∞
        ax.axhline(y=threshold, color='red', linestyle='--', alpha=0.7, label=f'–ü–æ—Ä–æ–≥ –∞–∫—Ç–∏–≤–∞—Ü–∏–∏ ({threshold})')
        
        for bar, prob in zip(bars, probabilities):
            height = bar.get_height()
            ax.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                   f'{prob:.1%}', ha='center', va='bottom', fontweight='bold')
        
        ax.legend()
        plt.xticks(rotation=45)
        plt.tight_layout()
        st.pyplot(fig)
        
        # –ê–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–∫–∏
        active_labels = result['sentiment']
        if active_labels:
            if result.get('subtype') == 'topic':
                st.write(f"**–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —Ç–µ–º–∞—Ç–∏–∫–∏:** {', '.join(active_labels)}")
            else:
                st.write(f"**–û–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ —ç–º–æ—Ü–∏–∏:** {', '.join(active_labels)}")
        else:
            st.write("**–ê–∫—Ç–∏–≤–Ω—ã–µ –º–µ—Ç–∫–∏:** –Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã")
    
    def run_model_comparison(self, tab, options):
        """–ó–∞–ø—É—Å–∫ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π"""
        with tab:
            st.header("üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π")
            
            if not self.model_metrics:
                st.warning("–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–µ–π –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                return
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ –≤—ã–±—Ä–∞–Ω–Ω—ã–º –º–æ–¥–µ–ª—è–º
            available_metrics = {
                model_id: metrics for model_id, metrics in self.model_metrics.items()
                if model_id in options['selected_models']
            }
            
            if not available_metrics:
                st.warning("–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –≤—ã–±—Ä–∞–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π")
                return
            
            # –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫
            st.subheader("üìã –°–≤–æ–¥–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫")
            
            metrics_df = pd.DataFrame(available_metrics).T
            metrics_df['model_name'] = [self.models[model_id]['name'] for model_id in available_metrics.keys()]
            metrics_df['category'] = [self.models[model_id]['category'] for model_id in available_metrics.keys()]
            
            # –û—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
            display_metrics = ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro', 
                             'inference_time', 'training_time']
            
            display_df = metrics_df[['model_name', 'category'] + display_metrics].round(3)
            
            # –°—Ç–∏–ª–∏–∑–∞—Ü–∏—è —Ç–∞–±–ª–∏—Ü—ã
            def highlight_max(s):
                if s.dtype in [np.float64, np.int64]:
                    is_max = s == s.max()
                    return ['background-color: lightgreen' if v else '' for v in is_max]
                return [''] * len(s)
            
            def highlight_min(s):
                if s.dtype in [np.float64, np.int64]:
                    is_min = s == s.min()
                    return ['background-color: lightcoral' if v else '' for v in is_min]
                return [''] * len(s)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Å—Ç–∏–ª–∏ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –º–µ—Ç—Ä–∏–∫–∏
            styled_df = display_df.style
            for metric in ['accuracy', 'f1_macro', 'precision_macro', 'recall_macro']:
                styled_df = styled_df.apply(highlight_max, subset=[metric])
            for metric in ['inference_time', 'training_time']:
                styled_df = styled_df.apply(highlight_min, subset=[metric])
            
            st.dataframe(styled_df)
            
            # –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            st.subheader("üìà –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # –ì—Ä–∞—Ñ–∏–∫ —Ç–æ—á–Ω–æ—Å—Ç–∏ –∏ F1
                fig1, ax1 = plt.subplots(figsize=(12, 6))
                x = range(len(available_metrics))
                width = 0.35
                
                models = list(available_metrics.keys())
                model_names = [self.models[model_id]['name'] for model_id in models]
                
                # –¶–≤–µ—Ç–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                category_colors = {
                    'classical_ml': '#339af0',
                    'neural_network': '#51cf66',
                    'transformer': '#ff6b6b',
                    'multilabel': '#cc5de8',
                    'automl': '#ff922b'
                }
                
                colors = [category_colors.get(self.models[model_id]['category'], '#ffd93d') 
                         for model_id in models]
                
                accuracy = [metrics['accuracy'] for metrics in available_metrics.values()]
                f1_scores = [metrics['f1_macro'] for metrics in available_metrics.values()]
                
                bars1 = ax1.bar([i - width/2 for i in x], accuracy, width, label='Accuracy', 
                               color=colors, alpha=0.7)
                bars2 = ax1.bar([i + width/2 for i in x], f1_scores, width, label='F1-score', 
                               color=colors, alpha=0.5)
                
                ax1.set_ylabel('Score')
                ax1.set_title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ Accuracy –∏ F1-score –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –º–æ–¥–µ–ª–µ–π')
                ax1.set_xticks(x)
                ax1.set_xticklabels(model_names, rotation=45, ha='right')
                ax1.legend()
                ax1.set_ylim(0, 1)
                ax1.grid(True, alpha=0.3)
                
                plt.tight_layout()
                st.pyplot(fig1)
            
            with col2:
                # –ì—Ä–∞—Ñ–∏–∫ –≤—Ä–µ–º–µ–Ω–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
                fig2, ax2 = plt.subplots(figsize=(12, 6))
                
                inference_times = [metrics['inference_time'] for metrics in available_metrics.values()]
                
                x = range(len(models))
                bars = ax2.bar(x, inference_times, color=colors, alpha=0.7)
                ax2.set_ylabel('–í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–º—Å)')
                ax2.set_title('–í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º')
                ax2.set_xticks(x)
                ax2.set_xticklabels(model_names, rotation=45, ha='right')
                ax2.grid(True, alpha=0.3)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ —Å—Ç–æ–ª–±—Ü—ã
                for bar, time_val in zip(bars, inference_times):
                    height = bar.get_height()
                    ax2.text(bar.get_x() + bar.get_width()/2., height + 0.1,
                           f'{time_val:.1f} –º—Å', ha='center', va='bottom', fontsize=8)
                
                plt.tight_layout()
                st.pyplot(fig2)
            
            # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≥—Ä–∞—Ñ–∏–∫–∏
            st.subheader("‚öñÔ∏è –ë–∞–ª–∞–Ω—Å –∫–∞—á–µ—Å—Ç–≤–∞ –∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
            
            col3, col4 = st.columns(2)
            
            with col3:
                # –¢–æ—á–Ω–æ—Å—Ç—å vs –≤—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è
                fig3, ax3 = plt.subplots(figsize=(10, 6))
                
                training_times = [metrics['training_time'] for metrics in available_metrics.values()]
                
                scatter = ax3.scatter(training_times, accuracy, c=colors, s=100, alpha=0.7)
                ax3.set_xlabel('–í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è (—Å–µ–∫)')
                ax3.set_ylabel('Accuracy')
                ax3.set_title('Accuracy vs –í—Ä–µ–º—è –æ–±—É—á–µ–Ω–∏—è')
                ax3.grid(True, alpha=0.3)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∏
                for i, name in enumerate(model_names):
                    ax3.annotate(name, (training_times[i], accuracy[i]), 
                               xytext=(5, 5), textcoords='offset points', fontsize=8)
                
                plt.tight_layout()
                st.pyplot(fig3)
            
            with col4:
                # F1-score vs —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
                fig4, ax4 = plt.subplots(figsize=(10, 6))
                
                model_sizes = [metrics['model_size'] for metrics in available_metrics.values()]
                
                scatter = ax4.scatter(model_sizes, f1_scores, c=colors, s=100, alpha=0.7)
                ax4.set_xlabel('–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ (–ú–ë)')
                ax4.set_ylabel('F1-score')
                ax4.set_title('F1-score vs –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏')
                ax4.grid(True, alpha=0.3)
                
                for i, name in enumerate(model_names):
                    ax4.annotate(name, (model_sizes[i], f1_scores[i]), 
                               xytext=(5, 5), textcoords='offset points', fontsize=8)
                
                plt.tight_layout()
                st.pyplot(fig4)
    
    def run_error_analysis(self, tab, options):
        """–ó–∞–ø—É—Å–∫ –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫"""
        with tab:
            st.header("üîç –ê–Ω–∞–ª–∏–∑ –æ—à–∏–±–æ–∫")
            
            if not self.error_data:
                st.warning("–î–∞–Ω–Ω—ã–µ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—à–∏–±–æ–∫ –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                return
            
            # –ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫
            st.subheader("üìä –ú–∞—Ç—Ä–∏—Ü—ã –æ—à–∏–±–æ–∫")
            
            if "confusion_matrices" in self.error_data:
                confusion_matrices = self.error_data["confusion_matrices"]
                
                # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –º–æ–¥–µ–ª–µ–π
                category_matrices = {}
                for model_id, cm in confusion_matrices.items():
                    if model_id in self.models:
                        category = self.models[model_id]['category']
                        if category not in category_matrices:
                            category_matrices[category] = []
                        category_matrices[category].append((model_id, cm))
                
                for category, matrices in category_matrices.items():
                    st.write(f"**{self._get_category_name(category)}**")
                    cols = st.columns(min(4, len(matrices)))
                    
                    for idx, (model_id, cm) in enumerate(matrices):
                        if idx < len(cols):
                            with cols[idx]:
                                model_name = self.models[model_id]['name']
                                st.write(f"**{model_name}**")
                                
                                fig, ax = plt.subplots(figsize=(6, 5))
                                sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                                           xticklabels=['Neg', 'Neu', 'Pos'],
                                           yticklabels=['Neg', 'Neu', 'Pos'])
                                ax.set_xlabel('–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
                                ax.set_ylabel('–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å')
                                plt.tight_layout()
                                st.pyplot(fig)
            
            # –ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫
            st.subheader("‚ùå –ü—Ä–∏–º–µ—Ä—ã –æ—à–∏–±–æ–∫ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
            
            if "error_examples" in self.error_data:
                for i, error in enumerate(self.error_data["error_examples"][:3]):
                    with st.expander(f"–ü—Ä–∏–º–µ—Ä –æ—à–∏–±–∫–∏ {i+1}"):
                        st.write(f"**–¢–µ–∫—Å—Ç:** {error['text']}")
                        st.write(f"**–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å:** {error['true_label']}")
                        
                        st.write("**–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–µ–π:**")
                        
                        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
                        category_predictions = {}
                        for model_id, prediction in error['predictions'].items():
                            if model_id in self.models:
                                category = self.models[model_id]['category']
                                if category not in category_predictions:
                                    category_predictions[category] = []
                                category_predictions[category].append((model_id, prediction))
                        
                        for category, predictions in category_predictions.items():
                            st.write(f"**{self._get_category_name(category)}:**")
                            for model_id, prediction in predictions:
                                model_name = self.models[model_id]['name']
                                if prediction == error['true_label']:
                                    st.write(f"‚úÖ {model_name}: {prediction}")
                                else:
                                    st.write(f"‚ùå {model_name}: {prediction}")
    
    def _get_category_name(self, category):
        """–ü–æ–ª—É—á–∏—Ç—å —á–∏—Ç–∞–µ–º–æ–µ –∏–º—è –∫–∞—Ç–µ–≥–æ—Ä–∏–∏"""
        category_names = {
            'classical_ml': '–ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ML',
            'neural_network': '–ù–µ–π—Ä–æ—Å–µ—Ç–∏',
            'transformer': '–¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã',
            'multilabel': 'Multilabel',
            'automl': 'AutoML'
        }
        return category_names.get(category, category)
    
    def run_metrics_analysis(self, tab, options):
        """–ê–Ω–∞–ª–∏–∑ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞"""
        with tab:
            st.header("üìà –ú–µ—Ç—Ä–∏–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞")
            
            if not self.model_metrics:
                st.warning("–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–µ–π –Ω–µ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")
                return

            # –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç –≤—ã—á–∏—Å–ª–∏—Ç–µ–ª—å–Ω—ã—Ö —Ä–µ—Å—É—Ä—Å–æ–≤
            st.subheader("‚ö° –ó–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –∫–∞—á–µ—Å—Ç–≤–∞ –æ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤")
            
            col1, col2 = st.columns(2)
            
            with col1:
                # –ö–∞—á–µ—Å—Ç–≤–æ vs –≤—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
                fig1, ax1 = plt.subplots(figsize=(12, 8))
                
                models = list(self.model_metrics.keys())
                accuracy = [self.model_metrics[model_id]['accuracy'] for model_id in models]
                inference_times = [self.model_metrics[model_id]['inference_time'] for model_id in models]
                model_names = [self.models[model_id]['name'] for model_id in models]
                
                # –†–∞–∑–Ω—ã–µ —Ü–≤–µ—Ç–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
                category_colors = {
                    'classical_ml': '#339af0',
                    'neural_network': '#51cf66',
                    'transformer': '#ff6b6b',
                    'multilabel': '#cc5de8',
                    'automl': '#ff922b'
                }
                
                colors = []
                sizes = []
                for model_id in models:
                    category = self.models[model_id]['category']
                    colors.append(category_colors.get(category, '#ffd93d'))
                    
                    # –†–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
                    if category == 'classical_ml':
                        sizes.append(100)
                    elif category == 'neural_network':
                        sizes.append(120)
                    elif category == 'transformer':
                        sizes.append(140)
                    elif category == 'multilabel':
                        sizes.append(110)
                    elif category == 'automl':
                        sizes.append(130)
                    else:
                        sizes.append(80)
                
                scatter = ax1.scatter(inference_times, accuracy, c=colors, s=sizes, alpha=0.7)
                ax1.set_xlabel('–í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è (–º—Å)')
                ax1.set_ylabel('Accuracy')
                ax1.set_title('–ö–∞—á–µ—Å—Ç–≤–æ vs –í—Ä–µ–º—è –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º –º–æ–¥–µ–ª–µ–π')
                ax1.grid(True, alpha=0.3)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–¥–ø–∏—Å–∏
                for i, name in enumerate(model_names):
                    ax1.annotate(name, (inference_times[i], accuracy[i]), 
                               xytext=(5, 5), textcoords='offset points', fontsize=8)
                
                # –õ–µ–≥–µ–Ω–¥–∞
                from matplotlib.lines import Line2D
                legend_elements = [
                    Line2D([0], [0], marker='o', color='w', markerfacecolor='#339af0', 
                          markersize=10, label='Classical ML'),
                    Line2D([0], [0], marker='o', color='w', markerfacecolor='#51cf66', 
                          markersize=10, label='Neural Networks'),
                    Line2D([0], [0], marker='o', color='w', markerfacecolor='#ff6b6b', 
                          markersize=10, label='Transformers'),
                    Line2D([0], [0], marker='o', color='w', markerfacecolor='#cc5de8', 
                          markersize=10, label='Multilabel'),
                    Line2D([0], [0], marker='o', color='w', markerfacecolor='#ff922b', 
                          markersize=10, label='AutoML')
                ]
                ax1.legend(handles=legend_elements, loc='lower right')
                
                plt.tight_layout()
                st.pyplot(fig1)
            
            with col2:
                # –ö–∞—á–µ—Å—Ç–≤–æ vs —Ä–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏
                fig2, ax2 = plt.subplots(figsize=(12, 8))
                
                model_sizes = [self.model_metrics[model_id]['model_size'] for model_id in models]
                
                scatter = ax2.scatter(model_sizes, accuracy, c=colors, s=sizes, alpha=0.7)
                ax2.set_xlabel('–†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ (–ú–ë)')
                ax2.set_ylabel('Accuracy')
                ax2.set_title('–ö–∞—á–µ—Å—Ç–≤–æ vs –†–∞–∑–º–µ—Ä –º–æ–¥–µ–ª–∏ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º')
                ax2.grid(True, alpha=0.3)
                
                for i, name in enumerate(model_names):
                    ax2.annotate(name, (model_sizes[i], accuracy[i]), 
                               xytext=(5, 5), textcoords='offset points', fontsize=8)
                
                ax2.legend(handles=legend_elements, loc='lower right')
                
                plt.tight_layout()
                st.pyplot(fig2)
            
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º
            st.subheader("üìä –ö–æ–º–ø–ª–µ–∫—Å–Ω–æ–µ —Å—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–µ—Ç—Ä–∏–∫")
            
            # –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ä–∞–¥–∏–∞–ª—å–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã
            if options['selected_models']:
                selected_models = options['selected_models']
            else:
                selected_models = list(self.model_metrics.keys())[:4]  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 4 –º–æ–¥–µ–ª–∏
            
            if len(selected_models) >= 2:
                # –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –¥–ª—è —Ä–∞–¥–∏–∞–ª—å–Ω–æ–π –¥–∏–∞–≥—Ä–∞–º–º—ã
                metrics_to_compare = ['accuracy', 'f1_macro', 'precision_macro', 
                                    'recall_macro', 'roc_auc', 'pr_auc']
                
                fig3 = plt.figure(figsize=(12, 8))
                
                # –í—ã—á–∏—Å–ª—è–µ–º —É–≥–ª—ã –¥–ª—è –æ—Å–µ–π
                angles = [n / float(len(metrics_to_compare)) * 2 * np.pi for n in range(len(metrics_to_compare))]
                angles += angles[:1]  # –ó–∞–º—ã–∫–∞–µ–º –∫—Ä—É–≥
                
                # –°–æ–∑–¥–∞–µ–º subplot
                ax = fig3.add_subplot(111, polar=True)
                
                # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ—Å–∏
                plt.xticks(angles[:-1], metrics_to_compare)
                
                # –î–ª—è –∫–∞–∂–¥–æ–π –º–æ–¥–µ–ª–∏ —Å—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ–∏–∫
                for i, model_id in enumerate(selected_models):
                    if model_id in self.model_metrics:
                        model_metrics = self.model_metrics[model_id]
                        values = [model_metrics[metric] for metric in metrics_to_compare]
                        values += values[:1]  # –ó–∞–º—ã–∫–∞–µ–º –∫—Ä—É–≥
                        
                        # –¶–≤–µ—Ç –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –∫–∞—Ç–µ–≥–æ—Ä–∏–∏
                        category = self.models[model_id]['category']
                        color = category_colors.get(category, '#ffd93d')
                        
                        ax.plot(angles, values, 'o-', linewidth=2, label=self.models[model_id]['name'], color=color)
                        ax.fill(angles, values, alpha=0.1, color=color)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –ª–µ–≥–µ–Ω–¥—É
                plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))
                plt.title('–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ –≤—Å–µ–º –º–µ—Ç—Ä–∏–∫–∞–º (—Ä–∞–¥–∞—Ä–Ω–∞—è –¥–∏–∞–≥—Ä–∞–º–º–∞)')
                st.pyplot(fig3)
            
            # –¢–∞–±–ª–∏—Ü–∞ —Å –ø–æ–ª–Ω—ã–º–∏ –º–µ—Ç—Ä–∏–∫–∞–º–∏
            st.subheader("üìã –ü–æ–ª–Ω–∞—è —Ç–∞–±–ª–∏—Ü–∞ –º–µ—Ç—Ä–∏–∫")
            
            full_metrics_df = pd.DataFrame(self.model_metrics).T
            full_metrics_df['model_name'] = [self.models[model_id]['name'] for model_id in self.model_metrics.keys()]
            full_metrics_df['category'] = [self.models[model_id]['category'] for model_id in self.model_metrics.keys()]
            
            # –£–ø–æ—Ä—è–¥–æ—á–∏–≤–∞–µ–º –∫–æ–ª–æ–Ω–∫–∏
            column_order = ['model_name', 'category', 'accuracy', 'f1_macro', 'precision_macro', 
                          'recall_macro', 'roc_auc', 'pr_auc', 'inference_time', 'training_time', 'model_size']
            full_metrics_df = full_metrics_df[column_order].round(3)
            
            st.dataframe(full_metrics_df)
    
    def run(self):
        """–û—Å–Ω–æ–≤–Ω–æ–π –º–µ—Ç–æ–¥ –∑–∞–ø—É—Å–∫–∞ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è"""
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –∏ –¥–∞–Ω–Ω—ã—Ö
        if not self.loaded:
            with st.spinner("üîÑ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–∏—Å—Ç–µ–º—É –∞–Ω–∞–ª–∏–∑–∞..."):
                if not self.load_all_models_and_data():
                    st.error("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å–∏—Å—Ç–µ–º—É. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Ñ–∞–π–ª–æ–≤.")
                    return
        
        # –ü–æ–ª—É—á–µ–Ω–∏–µ –Ω–∞—Å—Ç—Ä–æ–µ–∫ –∏–∑ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏
        options = self.create_sidebar()
        
        # –°–æ–∑–¥–∞–Ω–∏–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞ —Å –≤–∫–ª–∞–¥–∫–∞–º–∏
        tabs = self.create_main_interface()
        
        # –ó–∞–ø—É—Å–∫ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –∞–Ω–∞–ª–∏–∑–æ–≤ –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –≤–∫–ª–∞–¥–∫–∞—Ö
        self.run_text_classification(tabs[0], options)
        self.run_model_comparison(tabs[1], options)
        
        if len(tabs) > 2 and self.error_data:
            self.run_error_analysis(tabs[2], options)
            
        if len(tabs) > 3 and self.model_metrics:
            self.run_metrics_analysis(tabs[3], options)
        
        # –§—É—Ç–µ—Ä
        st.markdown("---")
        st.markdown("""
        <div style='text-align: center; color: gray;'>
        <i>–ö–æ–º–ø–ª–µ–∫—Å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ | –ö–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ ML + –ù–µ–π—Ä–æ—Å–µ—Ç–∏ + –¢—Ä–∞–Ω—Å—Ñ–æ—Ä–º–µ—Ä—ã + AutoML + Multilabel</i>
        </div>
        """, unsafe_allow_html=True)

def main():
    app = StableSentimentAnalysis()
    app.run()

if __name__ == "__main__":
    main()